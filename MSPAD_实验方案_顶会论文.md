# MSPAD方法顶会论文实验方案

**MSPAD: Multi-Scale Domain Adversarial Prototypical Anomaly Detection**

## 📋 目录

1. [实验概述](#实验概述)
2. [数据集与评估指标](#数据集与评估指标)
3. [对比实验设计](#对比实验设计)
4. [消融实验设计](#消融实验设计)
5. [参数敏感性分析](#参数敏感性分析)
6. [可视化实验设计](#可视化实验设计)
7. [实验执行计划](#实验执行计划)
8. [预期结果与发现](#预期结果与发现)
9. [实验配置与脚本](#实验配置与脚本)

---

## 实验概述

### 研究目标

本文旨在验证MSPAD方法在跨域异常检测任务中的有效性，通过系统性的实验设计证明：

1. **有效性**：MSPAD在多个数据集上优于现有SOTA方法
2. **必要性**：每个核心组件的独立贡献和协同作用
3. **鲁棒性**：方法对超参数的敏感性分析
4. **可解释性**：通过可视化分析理解方法的工作原理

### MSPAD核心创新点

1. **多尺度域对抗训练**：在TCN的多个中间层同时进行域判别，实现层次化域对齐
2. **原型网络分类器**：使用原型网络替代Deep SVDD，学习正常样本的原型表示
3. **加权多尺度损失**：不同层使用不同权重，强调高层语义特征的重要性

---

## 数据集与评估指标

### 数据集

| 数据集 | 类型 | 源域数量 | 目标域数量 | 特点 |
|--------|------|---------|-----------|------|
| **MSL** | 航天器遥测数据 | 27个通道 | 27个通道 | 跨通道迁移，标注充分 |
| **SMD** | 服务器监控数据 | 28台机器 | 28台机器 | 跨机器迁移，标注较少 |
| **Boiler** | 工业锅炉数据 | 多个工况 | 多个工况 | 跨工况迁移，领域差异大 |

### 评估指标

**主要指标**（用于论文主表）：
- **AUPRC** (Average Precision)：平均精度，适合类别不平衡场景
- **Best F1 Score**：最佳F1分数，平衡精确率和召回率

**辅助指标**（用于详细分析）：
- **Best Precision**：最佳精确率
- **Best Recall**：最佳召回率
- **ROC AUC**：ROC曲线下面积

**评估策略**：
- 每个数据集运行5次，报告平均值±标准差
- 使用固定随机种子（seed=1234）确保可复现性
- 使用最佳验证集性能的模型进行测试

---

## 对比实验设计

### 实验1：与SOTA方法对比（核心实验）

**目的**：验证MSPAD相对于现有方法的优势

#### 对比方法

| 方法 | 类型 | 特点 | 论文/来源 |
|------|------|------|----------|
| **DACAD** | Baseline | 单尺度域对抗 + Deep SVDD | 原始方法 |
| **CLUDA** | SOTA | 对比学习 + 域自适应 | 对比方法 |
| **MSPAD** | Ours | 多尺度域对抗 + 原型网络 | 本文方法 |

#### 实验配置

**数据集**：MSL, SMD, Boiler（全部）

**实验设置**：
- 每个数据集选择3-5个代表性源域
- 每个源域迁移到所有其他目标域
- 报告平均性能和标准差

**实验编号**：`Comp-1.1` 至 `Comp-1.N`

#### 预期结果

- MSPAD在所有数据集上优于DACAD（预期提升2-5% AUPRC）
- MSPAD在大多数设置下优于或与CLUDA相当
- 在领域差异大的场景下，MSPAD优势更明显

---

### 实验2：跨数据集泛化能力

**目的**：验证方法的泛化能力

**实验设置**：
- 在MSL上训练，在SMD上测试（跨数据集）
- 在SMD上训练，在Boiler上测试
- 对比不同方法的跨数据集性能

**实验编号**：`Comp-2.1` 至 `Comp-2.3`

---

### 实验3：不同领域差异程度下的性能

**目的**：分析方法在不同领域差异下的表现

**实验设置**：
- 选择领域差异小的源-目标对（如MSL中相似通道）
- 选择领域差异大的源-目标对（如MSL中不同子系统）
- 对比不同方法的性能变化

**实验编号**：`Comp-3.1` 至 `Comp-3.2`

---

## 消融实验设计

### 实验4：核心组件消融（最高优先级）

**目的**：验证每个核心改进的独立贡献

#### 实验4.1：Baseline对比

| 实验编号 | 配置 | 说明 | 预期结果 |
|---------|------|------|---------|
| **Abl-4.1** | DACAD (Baseline) | 单尺度域对抗 + Deep SVDD | 基准性能 |
| **Abl-4.2** | MSPAD (Full) | 多尺度域对抗 + 原型网络 + 加权损失 | 最优性能 |

**假设**：Abl-4.2 > Abl-4.1（预期提升2-5% AUPRC）

#### 实验4.2：多尺度域对抗的贡献

| 实验编号 | 配置 | 说明 | 预期结果 |
|---------|------|------|---------|
| **Abl-4.3** | 单尺度域对抗 + Deep SVDD | Baseline | 基准 |
| **Abl-4.4** | 多尺度域对抗 + Deep SVDD | 仅添加改进1 | 性能提升1-3% |
| **Abl-4.5** | 单尺度域对抗 + 原型网络 | 仅添加改进2 | 性能提升1-2% |
| **Abl-4.6** | 多尺度域对抗 + 原型网络 | 改进1+2 | 性能进一步提升 |

**假设**：
- Abl-4.4 > Abl-4.3：多尺度域对抗有效
- Abl-4.5 > Abl-4.3：原型网络有效
- Abl-4.6 > Abl-4.4 且 Abl-4.6 > Abl-4.5：两个改进有协同作用

#### 实验4.3：原型网络分类器的贡献

| 实验编号 | 配置 | 说明 | 预期结果 |
|---------|------|------|---------|
| **Abl-4.7** | 单尺度域对抗 + Deep SVDD | Baseline | 基准 |
| **Abl-4.8** | 单尺度域对抗 + 原型网络 | 仅替换分类器 | 性能提升 |
| **Abl-4.9** | 多尺度域对抗 + Deep SVDD | 仅添加多尺度 | 性能提升 |
| **Abl-4.10** | 多尺度域对抗 + 原型网络 | 改进1+2 | 最优 |

**假设**：
- Abl-4.8 > Abl-4.7：原型网络优于Deep SVDD
- Abl-4.10 > Abl-4.9：原型网络在多尺度域对抗下更有效

#### 实验4.4：加权多尺度损失的贡献

| 实验编号 | 配置 | 说明 | 预期结果 |
|---------|------|------|---------|
| **Abl-4.11** | 多尺度域对抗（均匀权重）+ 原型网络 | 改进1+2，均匀权重 | 基准 |
| **Abl-4.12** | 多尺度域对抗（加权[0.1,0.3,0.6]）+ 原型网络 | 改进1+2+3，默认权重 | 性能提升 |
| **Abl-4.13** | 多尺度域对抗（反向权重[0.6,0.3,0.1]）+ 原型网络 | 改进1+2，反向权重 | 性能下降 |

**假设**：
- Abl-4.12 > Abl-4.11：加权损失优于均匀权重
- Abl-4.12 > Abl-4.13：高层权重高更合理

---

### 实验5：多尺度域对抗深度分析

**目的**：深入理解多尺度域对抗的机制

#### 实验5.1：不同层的贡献分析

| 实验编号 | 使用的层 | 配置 | 说明 |
|---------|---------|------|------|
| **Abl-5.1** | 仅Layer 1（低层） | `use_layer_mask=[1,0,0]` | 仅低层域对抗 |
| **Abl-5.2** | 仅Layer 2（中层） | `use_layer_mask=[0,1,0]` | 仅中层域对抗 |
| **Abl-5.3** | 仅Layer 3（高层） | `use_layer_mask=[0,0,1]` | 仅高层域对抗 |
| **Abl-5.4** | Layer 1+2 | `use_layer_mask=[1,1,0]` | 低层+中层 |
| **Abl-5.5** | Layer 2+3 | `use_layer_mask=[0,1,1]` | 中层+高层 |
| **Abl-5.6** | Layer 1+3 | `use_layer_mask=[1,0,1]` | 低层+高层 |
| **Abl-5.7** | 所有层 | `use_layer_mask=[1,1,1]` | 完整配置 |

**假设**：
- Abl-5.3 > Abl-5.2 > Abl-5.1：高层特征更重要
- Abl-5.7 > 任何子集：所有层都有贡献
- Abl-5.5 > Abl-5.4：中高层组合优于低中层组合

#### 实验5.2：单尺度 vs 多尺度组合

| 实验编号 | 配置 | 说明 | 预期结果 |
|---------|------|------|---------|
| **Abl-5.8** | 仅单尺度（最终层） | `weight_loss_disc=0.5`, `weight_loss_ms_disc=0.0` | 基准 |
| **Abl-5.9** | 仅多尺度（所有层） | `weight_loss_disc=0.0`, `weight_loss_ms_disc=0.3` | 性能提升 |
| **Abl-5.10** | 单尺度 + 多尺度 | `weight_loss_disc=0.5`, `weight_loss_ms_disc=0.3` | 最优 |

**假设**：Abl-5.10 > Abl-5.9 > Abl-5.8：单尺度+多尺度组合最优

---

### 实验6：损失函数消融

**目的**：分析各个损失函数的相对重要性

| 实验编号 | 移除的损失 | 配置 | 预期影响 |
|---------|-----------|------|---------|
| **Abl-6.1** | 无 | MSPAD完整版 | 最优性能 |
| **Abl-6.2** | 单尺度域对抗 | `weight_loss_disc=0.0` | 性能下降 |
| **Abl-6.3** | 多尺度域对抗 | `weight_loss_ms_disc=0.0` | 性能下降 |
| **Abl-6.4** | 原型网络分类 | `weight_loss_pred=0.0` | 性能大幅下降 |
| **Abl-6.5** | 源域监督对比 | `weight_loss_src_sup=0.0` | 性能轻微下降 |
| **Abl-6.6** | 目标域注入对比 | `weight_loss_trg_inj=0.0` | 性能轻微下降 |

**假设**：
- Abl-6.4性能最差：分类损失最重要
- Abl-6.2和Abl-6.3性能下降：域对抗损失重要
- Abl-6.5和Abl-6.6影响较小：对比损失是辅助作用

---

## 参数敏感性分析

### 实验7：多尺度域对抗损失权重敏感性

**参数**：`weight_loss_ms_disc`

**参数范围**：`[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.7]`

**实验编号**：`Sens-7.1` 至 `Sens-7.7`

**分析维度**：
- 对AUPRC的影响
- 对Best F1 Score的影响
- 对训练稳定性的影响（损失曲线）

**预期结果**：
- 最优值可能在0.2-0.4之间
- 权重过大会导致域对抗过强，影响分类性能
- 权重过小会导致多尺度域对齐不充分

**可视化**：绘制参数值 vs 性能曲线

---

### 实验8：单尺度 vs 多尺度损失权重比例

**分析配置**：
- 固定 `weight_loss_disc = 0.5`
- 变化 `weight_loss_ms_disc`：`[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]`

**实验编号**：`Sens-8.1` 至 `Sens-8.9`

**预期结果**：
- 存在最优比例（如 0.5:0.3）
- 两者需要平衡

**可视化**：绘制权重比例 vs 性能热力图

---

### 实验9：多尺度层权重配置敏感性

**权重配置选项**：
- `[0.1, 0.3, 0.6]`：默认配置（低→高递增）
- `[0.33, 0.33, 0.34]`：均匀权重
- `[0.6, 0.3, 0.1]`：反向权重（低层权重高）
- `[0.0, 0.0, 1.0]`：仅高层
- `[0.2, 0.4, 0.4]`：中高层权重高
- `[0.5, 0.3, 0.2]`：低层权重较高
- `[0.0, 0.5, 0.5]`：仅中高层

**实验编号**：`Sens-9.1` 至 `Sens-9.7`

**预期结果**：
- 默认配置 `[0.1, 0.3, 0.6]` 最优：高层权重应该更大
- 均匀权重次优：不同层的重要性不同
- 反向权重性能较差：低层权重过大不合理

**可视化**：绘制不同权重配置的性能对比柱状图

---

### 实验10：原型网络margin参数敏感性

**参数**：`prototypical_margin`

**参数范围**：`[0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.5]`

**实验编号**：`Sens-10.1` 至 `Sens-10.8`

**分析维度**：
- 对分类性能的影响
- 对异常检测阈值的影响
- 对正常/异常样本分离度的影响

**预期结果**：
- 最优值可能在1.0-1.5之间
- margin过小会导致正常和异常样本分离不充分
- margin过大会导致训练困难

**可视化**：绘制margin值 vs 性能曲线，以及不同margin下的特征分布可视化

---

### 实验11：其他损失权重敏感性

**参数**：`weight_loss_disc`, `weight_loss_src_sup`, `weight_loss_trg_inj`

**参数范围**：
- `weight_loss_disc`: `[0.0, 0.1, 0.3, 0.5, 0.7, 1.0]`
- `weight_loss_src_sup`: `[0.0, 0.05, 0.1, 0.2, 0.3]`
- `weight_loss_trg_inj`: `[0.0, 0.05, 0.1, 0.2, 0.3]`

**实验编号**：`Sens-11.1` 至 `Sens-11.N`

**预期结果**：
- 存在最优权重组合
- 权重过大或过小都会降低性能

**可视化**：绘制多参数网格搜索的热力图

---

## 可视化实验设计

### 实验12：特征空间可视化

**目的**：理解MSPAD学习的特征表示

#### 实验12.1：t-SNE可视化

**内容**：
- 源域和目标域的特征分布（训练前后对比）
- 正常样本和异常样本的特征分布
- 不同方法（DACAD vs MSPAD）的特征分布对比

**实验设置**：
- 使用t-SNE将高维特征降维到2D
- 可视化源域和目标域样本的分布
- 可视化正常和异常样本的分离度

**实验编号**：`Viz-12.1` 至 `Viz-12.3`

**预期发现**：
- MSPAD能够更好地对齐源域和目标域特征
- MSPAD能够更好地分离正常和异常样本

---

#### 实验12.2：UMAP可视化

**内容**：使用UMAP作为t-SNE的补充，验证特征分布的稳定性

**实验编号**：`Viz-12.4` 至 `Viz-12.6`

---

### 实验13：域对齐可视化

**目的**：可视化多尺度域对抗的效果

#### 实验13.1：不同层的域判别器准确率

**内容**：
- 绘制训练过程中不同层域判别器的准确率曲线
- 对比单尺度（仅最终层）vs 多尺度（所有层）的域对齐效果

**实验编号**：`Viz-13.1`

**预期发现**：
- 多尺度域对抗能够同时对齐不同层次的特征
- 低层特征对齐更快，高层特征对齐更稳定

---

#### 实验13.2：域差异度量

**内容**：
- 计算源域和目标域特征之间的MMD距离
- 绘制训练过程中MMD距离的变化曲线
- 对比不同方法的域对齐效果

**实验编号**：`Viz-13.2`

**预期发现**：
- MSPAD能够更有效地减少域差异
- 多尺度域对抗比单尺度域对抗更有效

---

### 实验14：原型网络可视化

**目的**：理解原型网络的工作原理

#### 实验14.1：原型中心可视化

**内容**：
- 可视化学习到的正常样本原型中心
- 可视化异常样本到原型中心的距离分布
- 对比不同方法的原型表示

**实验编号**：`Viz-14.1`

**预期发现**：
- 原型网络能够学习到有意义的正常样本表示
- 异常样本距离原型中心更远

---

#### 实验14.2：异常分数分布

**内容**：
- 绘制正常样本和异常样本的异常分数分布直方图
- 对比不同方法的异常分数分布
- 分析不同阈值下的分类性能

**实验编号**：`Viz-14.2`

**预期发现**：
- MSPAD能够更好地分离正常和异常样本
- 异常分数分布更清晰，便于设置阈值

---

### 实验15：训练过程可视化

**目的**：分析训练动态

#### 实验15.1：损失函数曲线

**内容**：
- 绘制各个损失函数的训练曲线
- 对比不同消融实验的损失曲线
- 分析训练稳定性

**实验编号**：`Viz-15.1`

**预期发现**：
- MSPAD的损失函数收敛更稳定
- 多尺度域对抗损失有助于稳定训练

---

#### 实验15.2：性能曲线

**内容**：
- 绘制验证集AUPRC和F1 Score的训练曲线
- 对比不同方法的性能曲线
- 分析收敛速度和最终性能

**实验编号**：`Viz-15.2`

**预期发现**：
- MSPAD收敛更快
- MSPAD最终性能更高

---

### 实验16：注意力可视化（如果适用）

**目的**：理解模型关注的时间步

**内容**：
- 如果模型有注意力机制，可视化注意力权重
- 分析模型关注哪些时间步进行异常检测
- 对比正常样本和异常样本的注意力模式

**实验编号**：`Viz-16.1`

**预期发现**：
- 模型能够关注到异常发生的关键时间步
- 不同样本的注意力模式不同

---

### 实验17：混淆矩阵和ROC/PR曲线

**目的**：详细分析分类性能

#### 实验17.1：混淆矩阵

**内容**：
- 绘制最佳阈值下的混淆矩阵
- 对比不同方法的混淆矩阵
- 分析误分类模式

**实验编号**：`Viz-17.1`

---

#### 实验17.2：ROC和PR曲线

**内容**：
- 绘制ROC曲线和PR曲线
- 对比不同方法的曲线
- 计算AUC值

**实验编号**：`Viz-17.2`

**预期发现**：
- MSPAD的ROC和PR曲线更优
- AUC值更高

---

### 实验18：案例研究可视化

**目的**：通过具体案例展示方法效果

#### 实验18.1：成功案例

**内容**：
- 选择几个成功检测的异常案例
- 可视化时间序列、异常分数、真实标签
- 标注异常发生的时间点

**实验编号**：`Viz-18.1`

---

#### 实验18.2：失败案例分析

**内容**：
- 选择几个误分类的案例
- 分析失败原因
- 对比不同方法的处理方式

**实验编号**：`Viz-18.2`

**预期发现**：
- MSPAD在大多数案例上表现更好
- 失败案例主要集中在领域差异极大的场景

---

## 实验执行计划

### 阶段1：对比实验（Week 1-2，优先级：⭐⭐⭐⭐⭐）

**目标**：验证MSPAD相对于SOTA方法的优势

**实验**：
- Comp-1.1 至 Comp-1.N：与DACAD和CLUDA对比
- Comp-2.1 至 Comp-2.3：跨数据集泛化
- Comp-3.1 至 Comp-3.2：不同领域差异

**预期时间**：10-14天

**关键决策点**：如果MSPAD没有显著优于Baseline，需要重新审视模型设计

---

### 阶段2：核心消融实验（Week 3-4，优先级：⭐⭐⭐⭐⭐）

**目标**：验证每个核心组件的贡献

**实验**：
- Abl-4.1 至 Abl-4.13：核心组件消融
- Abl-5.1 至 Abl-5.10：多尺度域对抗深度分析
- Abl-6.1 至 Abl-6.6：损失函数消融

**预期时间**：10-12天

**关键发现**：哪些组件最重要？组件之间是否有协同作用？

---

### 阶段3：参数敏感性分析（Week 5-6，优先级：⭐⭐⭐）

**目标**：优化关键参数配置

**实验**：
- Sens-7.1 至 Sens-7.7：多尺度损失权重
- Sens-8.1 至 Sens-8.9：单尺度vs多尺度比例
- Sens-9.1 至 Sens-9.7：层权重配置
- Sens-10.1 至 Sens-10.8：原型网络margin
- Sens-11.1 至 Sens-11.N：其他损失权重

**预期时间**：12-15天

**关键发现**：最优参数配置

---

### 阶段4：可视化实验（Week 7，优先级：⭐⭐⭐）

**目标**：理解方法的工作原理

**实验**：
- Viz-12.1 至 Viz-12.6：特征空间可视化
- Viz-13.1 至 Viz-13.2：域对齐可视化
- Viz-14.1 至 Viz-14.2：原型网络可视化
- Viz-15.1 至 Viz-15.2：训练过程可视化
- Viz-16.1：注意力可视化（如果适用）
- Viz-17.1 至 Viz-17.2：混淆矩阵和曲线
- Viz-18.1 至 Viz-18.2：案例研究

**预期时间**：5-7天

**关键发现**：方法的可解释性和工作原理

---

### 快速验证路径（推荐先执行）

如果想快速验证MSPAD的有效性，建议按以下顺序执行：

1. **Baseline对比**（Comp-1.1）：1个实验，验证MSPAD整体优于DACAD
2. **核心组件消融**（Abl-4.1 至 Abl-4.6）：6个实验，验证每个改进的贡献
3. **关键可视化**（Viz-12.1, Viz-13.1, Viz-14.1）：3个可视化，理解方法原理

**快速验证总计**：约10个实验 + 3个可视化，约1-2周

---

## 预期结果与发现

### 主要发现

1. **MSPAD优于现有方法**
   - 在MSL、SMD、Boiler数据集上，MSPAD的AUPRC比DACAD提升2-5%
   - 在大多数设置下，MSPAD与CLUDA相当或更优
   - 在领域差异大的场景下，MSPAD优势更明显

2. **每个核心组件都有贡献**
   - 多尺度域对抗带来1-3% AUPRC提升
   - 原型网络带来1-2% AUPRC提升
   - 加权多尺度损失带来0.5-1% AUPRC提升
   - 组件之间有协同作用

3. **多尺度域对抗机制有效**
   - 高层特征对齐更重要
   - 所有层都有贡献，完整配置最优
   - 单尺度+多尺度组合最优

4. **参数敏感性分析**
   - 最优多尺度损失权重：`weight_loss_ms_disc ≈ 0.3`
   - 最优层权重配置：`[0.1, 0.3, 0.6]`（低→高递增）
   - 最优margin值：`prototypical_margin ≈ 1.0-1.5`

5. **可视化分析**
   - MSPAD能够更好地对齐源域和目标域特征
   - MSPAD能够更好地分离正常和异常样本
   - 多尺度域对抗能够同时对齐不同层次的特征

---

### 论文表格设计

#### 表1：主要结果对比（MSL, SMD, Boiler）

| Method | MSL (AUPRC) | MSL (F1) | SMD (AUPRC) | SMD (F1) | Boiler (AUPRC) | Boiler (F1) |
|--------|-------------|----------|-------------|----------|----------------|-------------|
| DACAD | X.XX ± X.XX | X.XX ± X.XX | X.XX ± X.XX | X.XX ± X.XX | X.XX ± X.XX | X.XX ± X.XX |
| CLUDA | X.XX ± X.XX | X.XX ± X.XX | X.XX ± X.XX | X.XX ± X.XX | X.XX ± X.XX | X.XX ± X.XX |
| MSPAD | **X.XX ± X.XX** | **X.XX ± X.XX** | **X.XX ± X.XX** | **X.XX ± X.XX** | **X.XX ± X.XX** | **X.XX ± X.XX** |

#### 表2：消融实验结果

| Configuration | MSL (AUPRC) | SMD (AUPRC) | Boiler (AUPRC) |
|---------------|-------------|-------------|----------------|
| Baseline (DACAD) | X.XX | X.XX | X.XX |
| + Multi-Scale DA | X.XX | X.XX | X.XX |
| + Prototypical Net | X.XX | X.XX | X.XX |
| + Weighted Loss | X.XX | X.XX | X.XX |
| MSPAD (Full) | **X.XX** | **X.XX** | **X.XX** |

#### 表3：参数敏感性分析

| Parameter | Value | MSL (AUPRC) | SMD (AUPRC) | Boiler (AUPRC) |
|-----------|-------|-------------|-------------|----------------|
| weight_loss_ms_disc | 0.0 | X.XX | X.XX | X.XX |
| | 0.1 | X.XX | X.XX | X.XX |
| | 0.2 | X.XX | X.XX | X.XX |
| | **0.3** | **X.XX** | **X.XX** | **X.XX** |
| | 0.4 | X.XX | X.XX | X.XX |
| | 0.5 | X.XX | X.XX | X.XX |

---

### 论文图表设计

#### 图1：主要结果对比柱状图
- 对比DACAD、CLUDA、MSPAD在三个数据集上的性能
- 使用误差棒显示标准差

#### 图2：消融实验结果柱状图
- 展示每个组件的贡献
- 使用不同颜色表示不同组件

#### 图3：t-SNE特征可视化
- 对比DACAD和MSPAD的特征分布
- 展示源域和目标域的对齐效果

#### 图4：域对齐可视化
- 展示不同层域判别器的准确率曲线
- 对比单尺度vs多尺度

#### 图5：参数敏感性曲线
- 展示关键参数对性能的影响
- 标注最优参数值

#### 图6：案例研究
- 展示成功检测的异常案例
- 可视化时间序列和异常分数

---

## 实验配置与脚本

### 基础配置（所有实验共享）

```python
基础超参数 = {
    'num_epochs': 20,
    'batch_size': 256,  # MSL和Boiler
    'batch_size': 128,  # SMD
    'eval_batch_size': 256,
    'learning_rate': 1e-4,
    'dropout': 0.1,
    'weight_decay': 1e-4,
    'num_channels_TCN': '128-256-512',
    'dilation_factor_TCN': 3,
    'kernel_size_TCN': 7,
    'hidden_dim_MLP': 1024,
    'queue_size': 98304,
    'momentum': 0.99,
    'seed': 1234,  # 固定随机种子
}
```

### MSPAD完整配置

```python
MSPAD完整配置 = {
    'algo_name': 'MSPAD',
    'weight_loss_disc': 0.5,          # 单尺度域对抗损失权重
    'weight_loss_ms_disc': 0.3,       # 多尺度域对抗损失权重
    'weight_loss_pred': 1.0,          # 原型网络分类损失权重
    'weight_loss_src_sup': 0.1,       # 源域监督对比损失权重
    'weight_loss_trg_inj': 0.1,       # 目标域注入对比损失权重
    'prototypical_margin': 1.0,       # 原型网络间隔参数
    'scale_weights': [0.1, 0.3, 0.6], # 多尺度层权重
}
```

### 实验脚本结构

```
experiments/
├── comparison/          # 对比实验
│   ├── run_comparison.py
│   └── config_comparison.py
├── ablation/            # 消融实验
│   ├── run_ablation.py
│   └── config_ablation.py
├── sensitivity/         # 参数敏感性分析
│   ├── run_sensitivity.py
│   └── config_sensitivity.py
└── visualization/       # 可视化实验
    ├── run_visualization.py
    └── plot_utils.py
```

---

## 注意事项

1. **实验可复现性**
   - 固定随机种子（seed=1234）
   - 保存所有实验配置和命令行参数
   - 记录GPU型号和CUDA版本

2. **资源管理**
   - 合理安排GPU资源，避免同时运行过多实验
   - 使用断点续传功能，避免重复实验
   - 定期备份实验结果和日志文件

3. **结果记录**
   - 每个实验保存详细的日志文件
   - 记录训练曲线、验证曲线、测试结果
   - 保存最佳模型和预测结果

4. **错误处理**
   - 实验失败时记录错误信息，便于调试
   - 设置超时机制，避免实验卡死
   - 定期检查实验结果，及时发现问题

5. **阶段性检查**
   - 每个阶段完成后检查结果，决定是否继续下一阶段
   - 如果核心实验失败，及时调整实验方案
   - 保持实验记录和文档的同步更新

---

## 总结

本实验方案涵盖了顶会论文所需的所有实验类型：

1. **对比实验**：验证MSPAD相对于SOTA方法的优势
2. **消融实验**：验证每个核心组件的贡献
3. **参数敏感性分析**：优化关键参数配置
4. **可视化实验**：理解方法的工作原理和可解释性

**建议执行顺序**：
1. 先执行快速验证路径（约1-2周）
2. 如果结果符合预期，继续执行完整实验方案（约6-7周）
3. 根据实验结果调整实验设计

**预期产出**：
- 完整的实验结果表格和图表
- 详细的实验分析报告
- 可复现的实验代码和配置
- 高质量的顶会论文

---

**文档版本**: 1.0  
**创建日期**: 2024  
**维护者**: MSPAD项目组

